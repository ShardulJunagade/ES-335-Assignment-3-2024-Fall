{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "df = pd.read_csv('data/Cleaned_Indian_Food_Dataset.csv')\n",
    "data = df['TranslatedInstructions']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna().reset_index(drop=True) # Drop any empty rows\n",
    "data = data[data.str.strip().ne(\"\")] # Drop any rows with only whitespace\n",
    "\n",
    "special_tokens = ['start', 'end', 'pad']\n",
    "\n",
    "formatted_data = [f\"start {instructions} end\" for instructions in data]\n",
    "\n",
    "def clean_and_tokenize(text):\n",
    "    if text is None or text.strip() == \"\":\n",
    "        return []\n",
    "    \n",
    "\n",
    "    text = text.replace('start', ' start ').replace('end', ' end ')\n",
    "    \n",
    "    text = re.sub(r'([.,!?])', r' \\1 ', text)  # Add spaces around punctuation marks\n",
    "    text = re.sub(r'\\s+', ' ', text).strip() # Remove extra spaces\n",
    "    segments = text.lower().split() # Split text into segments\n",
    "    \n",
    "    return segments \n",
    "\n",
    "corpus = []\n",
    "for text in formatted_data:\n",
    "    corpus.extend(clean_and_tokenize(text))\n",
    "\n",
    "corpus.extend(special_tokens)\n",
    "\n",
    "\n",
    "vocab = sorted(list(set(corpus)))\n",
    "word_to_index = {word: idx for idx, word in enumerate(vocab)}\n",
    "index_to_word = {idx: word for idx, word in enumerate(vocab)}\n",
    "\n",
    "assert 'pad' in word_to_index, \"pad token missing in the vocabulary!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_io_pairs(corpus, context_size):\n",
    "    X, y = [], []\n",
    "    for i in range(len(corpus) - context_size):\n",
    "        context = corpus[i:i + context_size]\n",
    "        target = corpus[i + context_size]\n",
    "        \n",
    "        # Pad the context to ensure context_size length\n",
    "        if len(context) < context_size:\n",
    "            context = ['pad'] * (context_size - len(context)) + context\n",
    "        \n",
    "        X.append(context)\n",
    "        y.append(target)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def create_training_data(context_size, batch_size):\n",
    "    X, y = create_io_pairs(corpus, context_size)\n",
    "    for i in range(5):\n",
    "        print(X[i], \"->\", y[i])\n",
    "        \n",
    "    X_idx = [[word_to_index[word] for word in sequence] for sequence in X]\n",
    "    Y_idx = [word_to_index[word] for word in y]\n",
    "\n",
    "    X_tensor = torch.tensor(X_idx, dtype=torch.long)\n",
    "    Y_tensor = torch.tensor(Y_idx, dtype=torch.long)\n",
    "\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_tensor, Y_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "    train_dataset = TensorDataset(X_train, Y_train)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    test_data_path = f\"assets/test_data_context_{context_size}.pt\"\n",
    "    torch.save((X_test, Y_test), test_data_path)\n",
    "    print(f\"Test data for context size {context_size} saved to {test_data_path}\")\n",
    "\n",
    "\n",
    "    return train_loader, X_test, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImprovedMLP(\n",
      "  (embedding): Embedding(14343, 100)\n",
      "  (fc1): Linear(in_features=500, out_features=256, bias=True)\n",
      "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (dropout1): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=256, out_features=14343, bias=True)\n",
      "  (activation_function): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class ImprovedMLP(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, dropout_rate, context_size, activation_function):\n",
    "        super(ImprovedMLP, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.fc1 = nn.Linear(embedding_dim * context_size, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).view(x.size(0), -1)\n",
    "        x = self.dropout1(self.activation_function(self.bn1(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "dropout_rate = 0.5\n",
    "context_size = 5\n",
    "activation_function = nn.ReLU()\n",
    "base= ImprovedMLP(vocab_size, embedding_dim, hidden_dim, dropout_rate, context_size, activation_function)\n",
    "print(base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "\n",
    "Multi-layer Perceptron \n",
    "\n",
    "1.  Embedding Layer (`embedding`) \n",
    "  - Maps discrete word indices into continuous vector representations (embeddings).\n",
    "  - Captures semantic meaning and relationships between words.\n",
    "  -  Shape:  `(vocab_size, embedding_dim)`\n",
    "  -  Parameters: \n",
    "    - `vocab_size`: Number of unique words in the vocabulary.\n",
    "    - `embedding_dim`: Dimension of the embedding space, determining the size of the vector representation for each word.\n",
    "\n",
    "2.  Fully Connected Layer (`fc1`) \n",
    "  - Transforms the input from the embedding space to a hidden representation.\n",
    "  - Allows the model to learn complex patterns.\n",
    "  -  Shape:  `(embedding_dim * context_size, hidden_dim)`\n",
    "  -  Parameters: \n",
    "    - `context_size`: Number of words considered as context for each input.\n",
    "    - `hidden_dim`: Number of neurons in the hidden layer, determining the complexity of the representation.\n",
    "\n",
    "3.  Batch Normalization (`bn1`) \n",
    "  - Normalizes the output from the previous layer across the batch.\n",
    "  - Stabilizes the training process and accelerates convergence, regularizes the model, and prevents overfitting.\n",
    "  -  Shape:  `(hidden_dim, 1)`\n",
    "  -  Parameters: \n",
    "    - `hidden_dim`: Number of neurons in the hidden layer that will be normalized.\n",
    "\n",
    "4.  Dropout Layer (`dropout1`) \n",
    "  - Randomly sets a fraction of the input units to 0 at each update during training.\n",
    "  - Prevents overfitting and encourages the model to learn more robust features that are not reliant on any specific input.\n",
    "  -  Shape:  1D\n",
    "  -  Parameters: \n",
    "    - `dropout_rate`: Proportion of neurons to drop during training (e.g., 0.5 means 50% are dropped).\n",
    "\n",
    "5.  Fully Connected Layer (`fc2`) \n",
    "  - Final layer that maps the hidden representation to the output space (the vocabulary size).\n",
    "  -  Shape:  `(hidden_dim, vocab_size)`\n",
    "  -  Parameters: \n",
    "    - `vocab_size`: Number of unique words in the vocabulary.\n",
    "\n",
    "6.  Activation Function \n",
    "  - Applies non-linear transformations to enable the model to capture intricate relationships within the data.\n",
    "  -  Parameters: \n",
    "    - `activation_function`: The specific activation function used (e.g., ReLU, Sigmoid, Tanh).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "def train_multiple_models(context_lengths, embedding_dims, activation_functions, random_seeds, vocab_size, batch_size):\n",
    "    results = []\n",
    "    \n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "    param_combinations = list(itertools.product(context_lengths, embedding_dims, activation_functions, random_seeds))\n",
    "\n",
    "    for context_size, embedding_dim, activation_fn, random_seed in param_combinations:\n",
    "        torch.manual_seed(random_seed)\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        train_loader, X_test, Y_test = create_training_data(context_size, batch_size)\n",
    "        \n",
    "        model = ImprovedMLP(vocab_size, embedding_dim, hidden_dim= 1024, dropout_rate=0.3,\n",
    "                            context_size=context_size, activation_function=activation_fn).to(device)\n",
    "        criterion = nn.NLLLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        print(f\"\\nTraining with context_size={context_size}, embedding_dim={embedding_dim}, \"\n",
    "              f\"activation_fn={activation_fn.__name__}, random_seed={random_seed}\")\n",
    "        \n",
    "        train_model(model, train_loader, criterion, optimizer, num_epochs=500)\n",
    "        \n",
    "        \n",
    "        model_filename = f\"models/model_context_{context_size}_emb_{embedding_dim}_act_{activation_fn.__name__}_seed_{random_seed}.pth\"\n",
    "        try:\n",
    "            torch.save(model.state_dict(), model_filename)\n",
    "            print(f\"Model saved to {model_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {e}\")\n",
    "        \n",
    "        results.append(model_filename)\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'to', 'begin', 'making', 'the'] -> masala\n",
      "['to', 'begin', 'making', 'the', 'masala'] -> karela\n",
      "['begin', 'making', 'the', 'masala', 'karela'] -> recipe\n",
      "['making', 'the', 'masala', 'karela', 'recipe'] -> ,\n",
      "['the', 'masala', 'karela', 'recipe', ','] -> de-seed\n",
      "Test data for context size 5 saved to assets/test_data_context_5.pt\n",
      "\n",
      "Training with context_size=5, embedding_dim=32, activation_fn=tanh, random_seed=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4096\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Call the function to train models on all combinations and download them\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_multiple_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext_lengths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_seeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModels saved:\u001b[39m\u001b[38;5;124m\"\u001b[39m, results)\n",
      "Cell \u001b[1;32mIn[19], line 40\u001b[0m, in \u001b[0;36mtrain_multiple_models\u001b[1;34m(context_lengths, embedding_dims, activation_functions, random_seeds, vocab_size, batch_size)\u001b[0m\n\u001b[0;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining with context_size=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, embedding_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     38\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mactivation_fn=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, random_seed=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 40\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# Save each model\u001b[39;00m\n\u001b[0;32m     43\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/model_context_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_emb_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_act_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactivation_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_seed_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrandom_seed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[19], line 5\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      4\u001b[0m     total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 5\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1133\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\multiprocessing\\queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\multiprocessing\\connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[0;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[1;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\multiprocessing\\connection.py:346\u001b[0m, in \u001b[0;36mPipeConnection._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_got_empty_message \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    344\u001b[0m             _winapi\u001b[38;5;241m.\u001b[39mPeekNamedPipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\multiprocessing\\connection.py:1084\u001b[0m, in \u001b[0;36mwait\u001b[1;34m(object_list, timeout)\u001b[0m\n\u001b[0;32m   1081\u001b[0m                 ready_objects\u001b[38;5;241m.\u001b[39madd(o)\n\u001b[0;32m   1082\u001b[0m                 timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1084\u001b[0m     ready_handles \u001b[38;5;241m=\u001b[39m \u001b[43m_exhaustive_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaithandle_to_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1086\u001b[0m     \u001b[38;5;66;03m# request that overlapped reads stop\u001b[39;00m\n\u001b[0;32m   1087\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ov \u001b[38;5;129;01min\u001b[39;00m ov_list:\n",
      "File \u001b[1;32mc:\\Users\\Soham\\anaconda3\\envs\\pytorch_env\\Lib\\multiprocessing\\connection.py:1016\u001b[0m, in \u001b[0;36m_exhaustive_wait\u001b[1;34m(handles, timeout)\u001b[0m\n\u001b[0;32m   1014\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m L:\n\u001b[1;32m-> 1016\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForMultipleObjects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m WAIT_TIMEOUT:\n\u001b[0;32m   1018\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "context_lengths = [5,10]\n",
    "embedding_dims = [32,64]\n",
    "activation_functions = [F.tanh,F.leaky_relu]\n",
    "random_seeds = [0,42]\n",
    "batch_size = 4096\n",
    "\n",
    "results = train_multiple_models(context_lengths, embedding_dims, activation_functions, random_seeds, len(vocab), batch_size)\n",
    "print(\"Models saved:\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "\n",
    "\n",
    "with open(\"assets/word_to_index.json\", \"r\") as f:\n",
    "    word_to_index = json.load(f)\n",
    "\n",
    "with open(\"assets/index_to_word.json\", \"r\") as f:\n",
    "    index_to_word = json.load(f)\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "context_size = 10 \n",
    "embedding_dim = 32 \n",
    "activation_function_name = \"leaky_relu\" \n",
    "seed = 42\n",
    "\n",
    "activation_function_map = {\n",
    "    \"tanh\": torch.tanh,\n",
    "    \"relu\": F.relu,\n",
    "    \"leaky_relu\": F.leaky_relu\n",
    "}\n",
    "activation_function = activation_function_map.get(activation_function_name, F.relu)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ImprovedMLP(vocab_size, embedding_dim, hidden_dim= 1024, dropout_rate=0.3,\n",
    "                    context_size=context_size, activation_function=activation_function).to(device)\n",
    "model_path = f\"models/model_context_{context_size}_emb_{embedding_dim}_act_{activation_function_name}_seed_{seed}.pth\"\n",
    "\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    print(\"Model loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Model file not found at {model_path}. Ensure the file exists.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Sequence (in indices): [9286, 9286, 9286, 9286, 9286, 9286, 8390, 8286, 1696, 3913]\n"
     ]
    }
   ],
   "source": [
    "def words_to_indices(words, word_to_index):\n",
    "    return [word_to_index[word] if word in word_to_index else word_to_index['pad'] for word in words]\n",
    "\n",
    "start_sequence_words = \"Mix milk and cream\" \n",
    "start_sequence_words = clean_and_tokenize(start_sequence_words)\n",
    "start_sequence_indices = words_to_indices(start_sequence_words, word_to_index)\n",
    "\n",
    "if len(start_sequence_indices) < context_size:\n",
    "    start_sequence_indices = [word_to_index['pad']] * (context_size - len(start_sequence_indices)) + start_sequence_indices\n",
    "\n",
    "print(\"Start Sequence (in indices):\", start_sequence_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Recipe: mix milk and cream , 2 1/2 cups of water and whisk and close it in the hot water for about 30 minutes . next , we will add the cabbage and mix it . cook for 2 minutes on a low flame . then add the carrots and potatoes and saute them till they are cooked . now add the boiled gram and dal mix and let the mixture simmer for 2 minutes . adjust salt to taste , cover and cook it for a longer . keep aside . once the vegetable potato has cooked add the dal to the prepared soya\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import json\n",
    "import re\n",
    "\n",
    "with open(\"assets/word_to_index.json\", \"r\") as f:\n",
    "    word_to_index = json.load(f)\n",
    "\n",
    "\n",
    "with open(\"assets/index_to_word.json\", \"r\") as f:\n",
    "    index_to_word = json.load(f)\n",
    "    index_to_word = {int(k): v for k, v in index_to_word.items()}\n",
    "\n",
    "\n",
    "vocab_size = len(word_to_index)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def generate_text(model, start_sequence, num_words, temperature=1.0):\n",
    "    model.eval()\n",
    "    generated = list(start_sequence)\n",
    "    for _ in range(num_words):\n",
    "        input_seq = torch.tensor(generated[-context_size:], dtype=torch.long).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(input_seq)\n",
    "        logits = output.squeeze(0) / temperature\n",
    "        next_word_idx = torch.multinomial(F.softmax(logits, dim=-1), num_samples=1).item()\n",
    "        generated.append(next_word_idx)\n",
    "        if index_to_word[next_word_idx] == 'end':\n",
    "            break\n",
    "    return ' '.join(index_to_word[idx] for idx in generated if index_to_word[idx] != 'pad')\n",
    "\n",
    "\n",
    "if len(start_sequence_indices) < context_size:\n",
    "    start_sequence_indices = [word_to_index['pad']] * (context_size - len(start_sequence_indices)) + start_sequence_indices\n",
    "\n",
    "generated_text = generate_text(model, start_sequence_indices, num_words= 100, temperature= 1)\n",
    "print(\"Generated Recipe:\", ''.join(generated_text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"assets/word_to_index.json\", \"w\") as f:\n",
    "    json.dump(word_to_index, f)\n",
    "\n",
    "with open(\"assets/index_to_word.json\", \"w\") as f:\n",
    "    json.dump(index_to_word, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
